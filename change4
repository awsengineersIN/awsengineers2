# lambda_function.py - Complete AWS Inventory Lambda with Simplified Region Handling

import os
import csv
import json
import importlib
import tempfile
import zipfile
import logging
import re
from pathlib import Path
from datetime import datetime

from util import assume, account_id_from_name, ou_id_from_name, accounts_in_ou

# Setup logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)
if logger.handlers:
    for handler in logger.handlers:
        logger.removeHandler(handler)
handler = logging.StreamHandler()
formatter = logging.Formatter('%(levelname)s: %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# Environment variables
SENDER = os.getenv("SENDER", None)
MEMBER_ROLE = os.getenv("MEMBER_READ_ROLE", "ResourceReadRole")

# Import your custom send_email function
from your_utils import send_email  # Replace with your actual import

# Resource mapping - Including EC2Volumes
RES_MAP = {
    "EC2": "ec2", 
    "EC2Volumes": "ec2_volumes",
    "S3": "s3", 
    "Lambda": "lambda_", 
    "RDS": "rds",
    "DynamoDB": "dynamodb", 
    "Glue": "glue", 
    "Eventbridge": "eventbridge",
    "StepFunctions": "stepfunctions", 
    "SecurityHub": "securityhub", 
    "Config": "config"
}

def validate_email(email):
    """Basic email validation"""
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return re.match(pattern, email) is not None

def write_csv(rows, headers, path):
    """Write CSV file with proper error handling"""
    try:
        with open(path, "w", newline="", encoding='utf-8') as fh:
            writer = csv.writer(fh)
            writer.writerow(headers)
            writer.writerows(rows)
        logger.info(f"CSV written successfully: {path} ({len(rows)} rows)")
    except Exception as e:
        logger.error(f"Failed to write CSV {path}: {e}")
        raise

def create_zip_archive(file_paths, zip_path):
    """Create ZIP archive from list of file paths"""
    try:
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=6) as zipf:
            for file_path in file_paths:
                if os.path.exists(file_path):
                    zipf.write(file_path, Path(file_path).name)
        logger.info(f"ZIP archive created: {zip_path}")
        return os.path.getsize(zip_path)
    except Exception as e:
        logger.error(f"Failed to create ZIP archive: {e}")
        raise

def build_email_body(scope, target, resources, regions_requested, accounts_processed, files_created, zip_size_bytes, recipients_count, account_region_summary):
    """Build detailed email body with inventory context and region information"""
    
    # Format file size for readability
    if zip_size_bytes < 1024:
        size_str = f"{zip_size_bytes} bytes"
    elif zip_size_bytes < 1024 * 1024:
        size_str = f"{zip_size_bytes / 1024:.1f} KB"
    else:
        size_str = f"{zip_size_bytes / (1024 * 1024):.1f} MB"
    
    # Build the email body
    body = f"""AWS Resource Inventory Report
=======================================

This inventory report has been sent to {recipients_count} recipient(s).

Inventory Request Details:
--------------------------
• Scope: {scope}
• Target: {target}
• Resources Requested: {', '.join(resources)}
• Regions Requested: {', '.join(regions_requested)}
• Generated: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC

Summary:
--------
• Accounts Processed: {accounts_processed}
• CSV Files Generated: {files_created}
• ZIP Archive Size: {size_str}

Regions Scanned per Account:
---------------------------
{account_region_summary}

Content:
--------
The attached ZIP file contains CSV exports for the following AWS resources:
"""
    
    for resource in resources:
        body += f"  • {resource}\n"
    
    body += f"""
Each CSV file is named in the format: <AccountName>_<ResourceType>.csv

Columns vary by resource type but typically include:
- Resource identifiers (ID/Name/ARN)
- Resource status and configuration
- Creation/modification dates
- Regional information

Note: 
- Only the requested regions are scanned for each account
- S3 buckets are collected globally from us-east-1 regardless of region selection
- Resources are returned only if found in the requested regions
- Multiple accounts can be specified using comma-separated format

For questions or support, please contact the AWS Infrastructure team.

---
This inventory was automatically generated by the AWS Resource Inventory System.
"""
    
    return body

def lambda_handler(event, context):
    """
    Main Lambda handler with simplified region handling
    
    Event format:
    
    Single Account:
    {
        "scope": "Account",
        "target": "Production-Account",
        "resources": ["EC2", "EC2Volumes", "S3"],
        "regions": ["us-east-1", "us-west-2"],
        "email": "ops@company.com"
    }
    
    Multiple Accounts (comma-separated):
    {
        "scope": "Account", 
        "target": "Account-1,Account-2,Account-3",
        "resources": ["EC2", "EC2Volumes", "S3"],
        "regions": ["us-east-1", "us-west-2"],
        "email": "ops@company.com"
    }
    
    OU:
    {
        "scope": "OU",
        "target": "Production-OU",
        "resources": ["EC2", "S3"],
        "regions": ["us-east-1"],
        "email": "ops@company.com"
    }
    """
    logger.info(f"Lambda invoked with event: {json.dumps(event)}")
    
    # Input validation
    required_fields = ['scope', 'target', 'resources', 'email']
    for field in required_fields:
        if field not in event or not event[field]:
            error_msg = f"Missing or empty required field: {field}"
            logger.error(error_msg)
            raise ValueError(error_msg)
    
    scope = event["scope"]
    target = event["target"]
    resources = event["resources"]
    email_input = event["email"]
    regions_requested = event.get("regions", ["us-east-1", "us-west-2"])  # Default regions
    
    if not SENDER:
        error_msg = "Missing SENDER environment variable"
        logger.error(error_msg)
        raise Exception(error_msg)
    
    # Parse multiple emails - handle both string and list formats
    if isinstance(email_input, str):
        recipients = [email.strip() for email in email_input.split(',') if email.strip()]
    elif isinstance(email_input, list):
        recipients = [email.strip() for email in email_input if email.strip()]
    else:
        raise ValueError("Email parameter must be a string or list")
    
    if not recipients:
        raise ValueError("No valid email addresses provided")
    
    # Validate all email addresses
    invalid_emails = [email for email in recipients if not validate_email(email)]
    if invalid_emails:
        raise ValueError(f"Invalid email addresses: {', '.join(invalid_emails)}")
    
    # Validate input formats
    if not isinstance(regions_requested, list):
        raise ValueError("Regions must be provided as a list")
    
    if not isinstance(resources, list):
        raise ValueError("Resources must be provided as a list")
    
    logger.info(f"Processing inventory for {len(recipients)} recipients: {recipients}")
    logger.info(f"Processing inventory: scope={scope}, target={target}, resources={resources}, regions={regions_requested}")
    
    # Resolve accounts based on scope
    accounts = []
    account_names = []
    
    if scope == "Account":
        # Parse TARGET for single or multiple accounts (comma-separated)
        account_names = [name.strip() for name in target.split(',') if name.strip()]
        
        logger.info(f"Resolving {len(account_names)} account names from TARGET: {account_names}")
        
        for account_name in account_names:
            try:
                account_id = account_id_from_name(account_name)
                accounts.append(account_id)
                logger.info(f"✅ Resolved '{account_name}' -> {account_id}")
            except Exception as e:
                logger.error(f"❌ Failed to resolve account '{account_name}': {e}")
                continue
                
    elif scope == "OU":
        # OU resolves to multiple accounts
        try:
            ou_id = ou_id_from_name(target)
            accounts = list(accounts_in_ou(ou_id))
            # For OU, we get account IDs, create display names for reporting
            account_names = [f"Account-{acc}" for acc in accounts]
            logger.info(f"OU '{target}' resolved to {len(accounts)} accounts")
        except Exception as e:
            raise ValueError(f"Failed to resolve OU '{target}': {e}")
    else:
        raise ValueError(f"Invalid scope: {scope}. Must be 'Account' or 'OU'")
    
    if not accounts:
        raise ValueError("No valid accounts resolved from the target")
    
    logger.info(f"Will process {len(accounts)} accounts: {account_names}")
    
    csv_files = []
    tmpdir = Path(tempfile.gettempdir())
    account_region_summary = {}  # Track which regions were attempted per account
    
    try:
        # Process each account
        for i, acct in enumerate(accounts):
            account_name = account_names[i] if i < len(account_names) else f"Account-{acct}"
            role_arn = f"arn:aws:iam::{acct}:role/{MEMBER_ROLE}"
            logger.info(f"Processing account {i+1}/{len(accounts)}: {account_name} ({acct})")
            
            try:
                session = assume(role_arn, "inventory-run")
                logger.info(f"✅ Successfully assumed role for account: {account_name}")
                
                # Use the regions passed in the event - no validation or filtering
                account_regions = regions_requested
                account_region_summary[account_name] = account_regions
                logger.info(f"Will scan account {account_name} in regions: {account_regions}")
                
            except Exception as e:
                logger.error(f"❌ Failed to assume role for account {account_name}: {e}")
                continue
            
            # Process each resource type for this account
            for res in resources:
                mod_name = RES_MAP.get(res)
                if not mod_name:
                    logger.warning(f"Unknown resource type: {res}")
                    continue
                
                try:
                    mod = importlib.import_module(f"resource_fetchers.{mod_name}")
                    logger.info(f"Loaded module for resource: {res}")
                except ImportError as e:
                    logger.error(f"Failed to import module for {res}: {e}")
                    continue
                
                try:
                    rows = []
                    # Use requested regions (except S3 which is always us-east-1)
                    regions_to_scan = ["us-east-1"] if res == "S3" else account_regions
                    
                    # Iterate through each requested region
                    for region in regions_to_scan:
                        try:
                            logger.info(f"Collecting {res} from {region} in account {account_name}")
                            region_rows = mod.collect(session, acct, region)
                            rows.extend(region_rows)
                            logger.info(f"✅ Collected {len(region_rows)} rows for {res} in {region} (account {account_name})")
                        except Exception as e:
                            logger.warning(f"⚠️ Failed to collect {res} from {region} in account {account_name}: {str(e)[:200]}")
                            # Continue to next region instead of failing completely
                            continue
                    
                    if not rows:
                        logger.info(f"ℹ️ No data found for {res} in account {account_name} across requested regions")
                        continue
                    
                    # Write CSV - use account name for filename
                    csv_name = f"{account_name}_{res}.csv"
                    csv_path = tmpdir / csv_name
                    write_csv(rows, mod.HEADERS, csv_path)
                    csv_files.append(str(csv_path))
                    logger.info(f"✅ Created CSV: {csv_name} with {len(rows)} rows")
                    
                except Exception as e:
                    logger.error(f"❌ Error collecting {res} for account {account_name}: {e}")
                    continue
        
        # Build account-region summary for email
        account_region_summary_text = "\n".join([
            f"• {acc_name}: {', '.join(regions)}"
            for acc_name, regions in account_region_summary.items()
        ])
        
        if not csv_files:
            logger.info("No data collected - sending notification email")
            
            # Build no-data email body
            no_data_body = f"""AWS Resource Inventory Report - No Data Found
=====================================================

This notification has been sent to {len(recipients)} recipient(s).

Inventory Request Details:
--------------------------
• Scope: {scope}
• Target: {target}
• Accounts Resolved: {', '.join(account_names)}
• Resources Requested: {', '.join(resources)}
• Regions Requested: {', '.join(regions_requested)}
• Generated: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC

Regions Scanned per Account:
---------------------------
{account_region_summary_text}

Result:
-------
No resources were found matching your criteria in the requested regions.

This could be due to:
- No resources of the requested types exist in the specified regions
- Resources exist but in different regions than requested
- Access permissions preventing resource discovery
- Network connectivity issues

Please verify:
1. The account names/OU name are correct
2. The cross-account IAM role has appropriate read permissions
3. Resources exist in the specified regions for each account

For assistance, please contact the AWS Infrastructure team.
"""
            
            try:
                # SEND ONLY ONE EMAIL - Fixed multiple email issue
                result = send_email(
                    sender_addr=SENDER,
                    receiver_addr=recipients,
                    email_subject=f"AWS Inventory - No Data Found ({len(account_names)} accounts)",
                    email_body=no_data_body,
                    email_attachment=None
                )
                logger.info(f"No-data notification sent to {len(recipients)} recipients: {result}")
                return {
                    "message": "No data found - notification sent", 
                    "recipients": recipients,
                    "accounts_processed": len(accounts),
                    "files_created": 0
                }
            except Exception as e:
                logger.error(f"Failed to send no-data notification: {e}")
                raise
        
        # Create ZIP archive
        timestamp = datetime.utcnow().strftime('%Y%m%d-%H%M%S')
        zip_filename = f"aws-inventory-{timestamp}.zip"
        zip_path = tmpdir / zip_filename
        
        zip_size = create_zip_archive(csv_files, zip_path)
        logger.info(f"Created ZIP archive with {len(csv_files)} files, size: {zip_size} bytes")
        
        # Build detailed email body
        email_body = build_email_body(
            scope=scope,
            target=target,
            resources=resources,
            regions_requested=regions_requested,
            accounts_processed=len(accounts),
            files_created=len(csv_files),
            zip_size_bytes=zip_size,
            recipients_count=len(recipients),
            account_region_summary=account_region_summary_text
        )
        
        # Build subject with context
        account_summary = f"{len(accounts)} account{'s' if len(accounts) > 1 else ''}"
        subject = f"AWS Resource Inventory - {account_summary} ({len(csv_files)} files)"
        
        try:
            # SEND ONLY ONE EMAIL - Fixed multiple email issue
            result = send_email(
                sender_addr=SENDER,
                receiver_addr=recipients,
                email_subject=subject,
                email_body=email_body,
                email_attachment=str(zip_path)
            )
            logger.info(f"Success email sent to {len(recipients)} recipients: {result}")
            
        except Exception as e:
            logger.error(f"Failed to send success email: {e}")
            raise
        
        return {
            "message": f"Successfully sent AWS inventory with {len(csv_files)} files to {len(recipients)} recipients",
            "recipients": recipients,
            "accounts_processed": len(accounts),
            "accounts_requested": account_names,
            "files_created": len(csv_files),
            "zip_size_bytes": zip_size,
            "scope": scope,
            "target": target,
            "resources": resources,
            "regions_requested": regions_requested,
            "account_regions": account_region_summary
        }
    
    except Exception as e:
        logger.error(f"Lambda execution failed: {str(e)}")
        raise
    
    finally:
        # Cleanup temporary files
        try:
            for file_path in csv_files:
                if os.path.exists(file_path):
                    os.remove(file_path)
            if 'zip_path' in locals() and os.path.exists(zip_path):
                os.remove(zip_path)
            logger.info("Temporary files cleaned up")
        except Exception as e:
            logger.warning(f"Failed to cleanup temporary files: {e}")
