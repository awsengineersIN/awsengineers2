# lambda_function.py - Complete AWS Inventory Lambda with Multiple Accounts Support

import os
import csv
import json
import importlib
import tempfile
import zipfile
import logging
import re
from pathlib import Path
from datetime import datetime

from util import assume, account_id_from_name, ou_id_from_name, accounts_in_ou

# Setup logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)
if logger.handlers:
    for handler in logger.handlers:
        logger.removeHandler(handler)
handler = logging.StreamHandler()
formatter = logging.Formatter('%(levelname)s: %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# Environment variables
SENDER = os.getenv("SENDER", None)
MEMBER_ROLE = os.getenv("MEMBER_READ_ROLE", "ResourceReadRole")
FALLBACK_REGIONS = os.getenv("FALLBACK_REGIONS", "us-east-1,us-west-2").split(",")

# Import your custom send_email function
from your_utils import send_email  # Replace with your actual import

# Resource mapping - Including EC2Volumes
RES_MAP = {
    "EC2": "ec2", 
    "EC2Volumes": "ec2_volumes",
    "S3": "s3", 
    "Lambda": "lambda_", 
    "RDS": "rds",
    "DynamoDB": "dynamodb", 
    "Glue": "glue", 
    "Eventbridge": "eventbridge",
    "StepFunctions": "stepfunctions", 
    "SecurityHub": "securityhub", 
    "Config": "config"
}

def validate_email(email):
    """Basic email validation"""
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return re.match(pattern, email) is not None

def get_enabled_regions_for_account(session, account_id):
    """
    Dynamically discover enabled regions for an account
    Uses EC2 describe_regions() which only returns enabled regions
    """
    try:
        # Create EC2 client from us-east-1 (always enabled by default)
        ec2_client = session.client('ec2', region_name='us-east-1')
        
        # Get only enabled regions for this account
        response = ec2_client.describe_regions()
        enabled_regions = [region['RegionName'] for region in response['Regions']]
        
        # Filter out regions that might be enabling/disabling
        stable_regions = []
        for region in enabled_regions:
            try:
                # Quick test to ensure region is actually accessible
                regional_ec2 = session.client('ec2', region_name=region)
                regional_ec2.describe_vpcs(MaxResults=1)
                stable_regions.append(region)
            except Exception as e:
                logger.warning(f"Region {region} not fully accessible for account {account_id}: {str(e)[:100]}")
                continue
        
        if stable_regions:
            logger.info(f"Account {account_id} has {len(stable_regions)} enabled regions: {stable_regions}")
            return stable_regions
        else:
            logger.warning(f"No stable regions found for account {account_id}, using fallback")
            return FALLBACK_REGIONS
        
    except Exception as e:
        logger.warning(f"Failed to discover regions for account {account_id}: {e}")
        logger.info(f"Using fallback regions for account {account_id}: {FALLBACK_REGIONS}")
        return FALLBACK_REGIONS

def write_csv(rows, headers, path):
    """Write CSV file with proper error handling"""
    try:
        with open(path, "w", newline="", encoding='utf-8') as fh:
            writer = csv.writer(fh)
            writer.writerow(headers)
            writer.writerows(rows)
        logger.info(f"CSV written successfully: {path} ({len(rows)} rows)")
    except Exception as e:
        logger.error(f"Failed to write CSV {path}: {e}")
        raise

def create_zip_archive(file_paths, zip_path):
    """Create ZIP archive from list of file paths"""
    try:
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=6) as zipf:
            for file_path in file_paths:
                if os.path.exists(file_path):
                    zipf.write(file_path, Path(file_path).name)
        logger.info(f"ZIP archive created: {zip_path}")
        return os.path.getsize(zip_path)
    except Exception as e:
        logger.error(f"Failed to create ZIP archive: {e}")
        raise

def build_email_body(scope, target, resources, regions_requested, accounts_processed, files_created, zip_size_bytes, recipients_count, account_region_summary):
    """Build detailed email body with inventory context and region information"""
    
    # Format file size for readability
    if zip_size_bytes < 1024:
        size_str = f"{zip_size_bytes} bytes"
    elif zip_size_bytes < 1024 * 1024:
        size_str = f"{zip_size_bytes / 1024:.1f} KB"
    else:
        size_str = f"{zip_size_bytes / (1024 * 1024):.1f} MB"
    
    # Build the email body
    body = f"""AWS Resource Inventory Report
=======================================

This inventory report has been sent to {recipients_count} recipient(s).

Inventory Request Details:
--------------------------
• Scope: {scope}
• Target: {target}
• Resources Requested: {', '.join(resources)}
• Regions Requested: {', '.join(regions_requested)}
• Generated: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC

Summary:
--------
• Accounts Processed: {accounts_processed}
• CSV Files Generated: {files_created}
• ZIP Archive Size: {size_str}

Regions Used per Account:
------------------------
{account_region_summary}

Content:
--------
The attached ZIP file contains CSV exports for the following AWS resources:
"""
    
    for resource in resources:
        body += f"  • {resource}\n"
    
    body += f"""
Each CSV file is named in the format: <AccountName>_<ResourceType>.csv

Columns vary by resource type but typically include:
- Resource identifiers (ID/Name/ARN)
- Resource status and configuration
- Creation/modification dates
- Regional information

Note: 
- For regional resources, only the requested regions are scanned
- S3 buckets are collected globally from us-east-1 regardless of region selection
- Regions are filtered to only include those enabled in each account
- Multiple accounts can be specified using comma-separated format

For questions or support, please contact the AWS Infrastructure team.

---
This inventory was automatically generated by the AWS Resource Inventory System.
"""
    
    return body

def lambda_handler(event, context):
    """
    Main Lambda handler with multiple account support and region parameter support
    
    Event format:
    
    Single Account:
    {
        "scope": "Account",
        "target": "Production-Account",
        "resources": ["EC2", "EC2Volumes", "S3"],
        "regions": ["us-east-1", "us-west-2"],
        "email": "ops@company.com"
    }
    
    Multiple Accounts (comma-separated):
    {
        "scope": "Account", 
        "target": "Account-1,Account-2,Account-3",
        "resources": ["EC2", "EC2Volumes", "S3"],
        "regions": ["us-east-1", "us-west-2"],
        "email": "ops@company.com"
    }
    
    OU (unchanged):
    {
        "scope": "OU",
        "target": "Production-OU",
        "resources": ["EC2", "S3"],
        "regions": ["us-east-1"],
        "email": "ops@company.com"
    }
    """
    logger.info(f"Lambda invoked with event: {json.dumps(event)}")
    
    # Input validation
    required_fields = ['scope', 'target', 'resources', 'email']
    for field in required_fields:
        if field not in event or not event[field]:
            error_msg = f"Missing or empty required field: {field}"
            logger.error(error_msg)
            raise ValueError(error_msg)
    
    scope = event["scope"]
    target = event["target"]
    resources = event["resources"]
    email_input = event["email"]
    regions_requested = event.get("regions", ["us-east-1", "us-west-2"])  # Default regions
    
    if not SENDER:
        error_msg = "Missing SENDER environment variable"
        logger.error(error_msg)
        raise Exception(error_msg)
    
    # Parse multiple emails - handle both string and list formats
    if isinstance(email_input, str):
        recipients = [email.strip() for email in email_input.split(',') if email.strip()]
    elif isinstance(email_input, list):
        recipients = [email.strip() for email in email_input if email.strip()]
    else:
        raise ValueError("Email parameter must be a string or list")
    
    if not recipients:
        raise ValueError("No valid email addresses provided")
    
    # Validate all email addresses
    invalid_emails = [email for email in recipients if not validate_email(email)]
    if invalid_emails:
        raise ValueError(f"Invalid email addresses: {', '.join(invalid_emails)}")
    
    # Validate input formats
    if not isinstance(regions_requested, list):
        raise ValueError("Regions must be provided as a list")
    
    if not isinstance(resources, list):
        raise ValueError("Resources must be provided as a list")
    
    logger.info(f"Processing inventory for {len(recipients)} recipients: {recipients}")
    logger.info(f"Processing inventory: scope={scope}, target={target}, resources={resources}, regions={regions_requested}")
    
    # Resolve accounts based on scope
    accounts = []
    account_names = []
    
    if scope == "Account":
        # Parse TARGET for single or multiple accounts (comma-separated)
        account_names = [name.strip() for name in target.split(',') if name.strip()]
        
        logger.info(f"Resolving {len(account_names)} account names from TARGET: {account_names}")
        
        for account_name in account_names:
            try:
                account_id = account_id_from_name(account_name)
                accounts.append(account_id)
                logger.info(f"✅ Resolved '{account_name}' -> {account_id}")
            except Exception as e:
                logger.error(f"❌ Failed to resolve account '{account_name}': {e}")
                continue
                
    elif scope == "OU":
        # OU resolves to multiple accounts (unchanged)
        try:
            ou_id = ou_id_from_name(target)
            accounts = list(accounts_in_ou(ou_id))
            # For OU, we get account IDs, create display names for reporting
            account_names = [f"Account-{acc}" for acc in accounts]
            logger.info(f"OU '{target}' resolved to {len(accounts)} accounts")
        except Exception as e:
            raise ValueError(f"Failed to resolve OU '{target}': {e}")
    else:
        raise ValueError(f"Invalid scope: {scope}. Must be 'Account' or 'OU'")
    
    if not accounts:
        raise ValueError("No valid accounts resolved from the target")
    
    logger.info(f"Will process {len(accounts)} accounts: {account_names}")
    
    csv_files = []
    tmpdir = Path(tempfile.gettempdir())
    account_region_map = {}  # Track regions used per account
    
    try:
        # Process each account
        for i, acct in enumerate(accounts):
            account_name = account_names[i] if i < len(account_names) else f"Account-{acct}"
            role_arn = f"arn:aws:iam::{acct}:role/{MEMBER_ROLE}"
            logger.info(f"Processing account {i+1}/{len(accounts)}: {account_name} ({acct})")
            
            try:
                session = assume(role_arn, "inventory-run")
                logger.info(f"✅ Successfully assumed role for account: {account_name}")
                
                # Determine regions to use for this account
                if regions_requested:
                    # Use user-specified regions, but validate they're enabled
                    try:
                        enabled_regions = get_enabled_regions_for_account(session, acct)
                        # Filter requested regions to only those enabled in this account
                        account_regions = [r for r in regions_requested if r in enabled_regions]
                        if not account_regions:
                            logger.warning(f"None of the requested regions {regions_requested} are enabled in account {account_name}")
                            account_regions = enabled_regions[:2]  # Use first 2 enabled regions as fallback
                    except Exception as e:
                        logger.error(f"Failed to validate regions for account {account_name}: {e}")
                        account_regions = regions_requested  # Use requested regions anyway
                else:
                    # Fall back to dynamic discovery if no regions specified
                    account_regions = get_enabled_regions_for_account(session, acct)
                
                account_region_map[account_name] = account_regions
                logger.info(f"Will scan account {account_name} in regions: {account_regions}")
                
            except Exception as e:
                logger.error(f"❌ Failed to assume role for account {account_name}: {e}")
                continue
            
            # Process each resource type for this account
            for res in resources:
                mod_name = RES_MAP.get(res)
                if not mod_name:
                    logger.warning(f"Unknown resource type: {res}")
                    continue
                
                try:
                    mod = importlib.import_module(f"resource_fetchers.{mod_name}")
                    logger.info(f"Loaded module for resource: {res}")
                except ImportError as e:
                    logger.error(f"Failed to import module for {res}: {e}")
                    continue
                
                try:
                    rows = []
                    # Use account-specific regions (except S3 which is global)
                    regions_to_scan = ["us-east-1"] if res == "S3" else account_regions
                    
                    for region in regions_to_scan:
                        try:
                            region_rows = mod.collect(session, acct, region)
                            rows.extend(region_rows)
                            logger.info(f"Collected {len(region_rows)} rows for {res} in {region} (account {account_name})")
                        except Exception as e:
                            logger.error(f"Failed to collect {res} from {region} in account {account_name}: {str(e)[:200]}")
                            continue
                    
                    if not rows:
                        logger.info(f"No data found for {res} in account {account_name}")
                        continue
                    
                    # Write CSV - use account name for filename
                    csv_name = f"{account_name}_{res}.csv"
                    csv_path = tmpdir / csv_name
                    write_csv(rows, mod.HEADERS, csv_path)
                    csv_files.append(str(csv_path))
                    
                except Exception as e:
                    logger.error(f"Error collecting {res} for account {account_name}: {e}")
                    continue
        
        # Build account-region summary for email
        account_region_summary = "\n".join([
            f"• {acc_name}: {', '.join(regions)}"
            for acc_name, regions in account_region_map.items()
        ])
        
        if not csv_files:
            logger.info("No data collected - sending notification email")
            
            # Build no-data email body with context
            no_data_body = f"""AWS Resource Inventory Report - No Data Found
=====================================================

This notification has been sent to {len(recipients)} recipient(s).

Inventory Request Details:
--------------------------
• Scope: {scope}
• Target: {target}
• Accounts Resolved: {', '.join(account_names)}
• Resources Requested: {', '.join(resources)}
• Regions Requested: {', '.join(regions_requested)}
• Generated: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC

Regions Attempted per Account:
-----------------------------
{account_region_summary}

Result:
-------
No resources were found matching your criteria.

This could be due to:
- No resources of the requested types exist in the specified accounts
- Access permissions preventing resource discovery
- All resources in the specified regions being filtered out

Please verify:
1. The account names/OU name are correct
2. The cross-account IAM role has appropriate read permissions
3. Resources exist in the specified regions for each account

For assistance, please contact the AWS Infrastructure team.
"""
            
            try:
                result = send_email(
                    sender_addr=SENDER,
                    receiver_addr=recipients,
                    email_subject=f"AWS Inventory - No Data Found ({len(account_names)} accounts)",
                    email_body=no_data_body,
                    email_attachment=None
                )
                logger.info(f"No-data notification result: {result}")
                return {"message": "No data found - notification sent", "recipients": recipients}
            except Exception as e:
                logger.error(f"Failed to send no-data notification: {e}")
                raise
        
        # Create ZIP archive
        timestamp = datetime.utcnow().strftime('%Y%m%d-%H%M%S')
        zip_filename = f"aws-inventory-{timestamp}.zip"
        zip_path = tmpdir / zip_filename
        
        zip_size = create_zip_archive(csv_files, zip_path)
        logger.info(f"Created ZIP archive with {len(csv_files)} files, size: {zip_size} bytes")
        
        # Build detailed email body with context and region information
        email_body = build_email_body(
            scope=scope,
            target=target,
            resources=resources,
            regions_requested=regions_requested,
            accounts_processed=len(accounts),
            files_created=len(csv_files),
            zip_size_bytes=zip_size,
            recipients_count=len(recipients),
            account_region_summary=account_region_summary
        )
        
        # Build subject with context
        account_summary = f"{len(accounts)} account{'s' if len(accounts) > 1 else ''}"
        subject = f"AWS Resource Inventory - {account_summary} ({len(csv_files)} files)"
        
        try:
            result = send_email(
                sender_addr=SENDER,
                receiver_addr=recipients,
                email_subject=subject,
                email_body=email_body,
                email_attachment=str(zip_path)
            )
            logger.info(f"Email send result: {result}")
            
        except Exception as e:
            logger.error(f"Failed to send email: {e}")
            raise
        
        return {
            "message": f"Successfully sent AWS inventory with {len(csv_files)} files to {len(recipients)} recipients",
            "recipients": recipients,
            "accounts_processed": len(accounts),
            "accounts_requested": account_names,
            "files_created": len(csv_files),
            "zip_size_bytes": zip_size,
            "scope": scope,
            "target": target,
            "resources": resources,
            "regions_requested": regions_requested,
            "account_regions": account_region_map
        }
    
    except Exception as e:
        logger.error(f"Lambda execution failed: {str(e)}")
        raise
    
    finally:
        # Cleanup temporary files
        try:
            for file_path in csv_files:
                if os.path.exists(file_path):
                    os.remove(file_path)
            if 'zip_path' in locals() and os.path.exists(zip_path):
                os.remove(zip_path)
            logger.info("Temporary files cleaned up")
        except Exception as e:
            logger.warning(f"Failed to cleanup temporary files: {e}")
