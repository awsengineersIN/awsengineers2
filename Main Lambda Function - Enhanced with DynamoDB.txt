import json
import boto3
import logging
import os
from datetime import datetime
import uuid

logger = logging.getLogger()
logger.setLevel(logging.INFO)

ssm = boto3.client('ssm')
ec2 = boto3.client('ec2')
stepfunctions = boto3.client('stepfunctions')
dynamodb = boto3.resource('dynamodb')

def lambda_handler(event, context):
    """
    Analyzes maintenance window execution failures and triggers remediation
    Enhanced with DynamoDB tracking and learning capabilities
    """
    try:
        detail = event.get('detail', {})
        execution_id = detail.get('maintenance-window-execution-id')
        window_id = detail.get('maintenance-window-id')
        status = detail.get('status')
        
        # Check dry-run mode from environment variable or payload
        global_dry_run = os.environ.get('DRY_RUN_MODE', 'false').lower() == 'true'
        payload_dry_run = event.get('dry_run', False)
        dry_run_enabled = global_dry_run or payload_dry_run
        
        logger.info(f"Processing maintenance window execution {execution_id} with status {status}")
        logger.info(f"Dry-run mode - Global: {global_dry_run}, Payload: {payload_dry_run}, Effective: {dry_run_enabled}")
        
        # Only process failed or timed out executions
        if status not in ['FAILED', 'TIMED_OUT']:
            logger.info(f"Status {status} does not require remediation")
            return {'statusCode': 200, 'body': 'No remediation required'}
        
        # Get detailed execution information
        failed_instances = get_failed_instances(execution_id)
        
        if not failed_instances:
            logger.info("No failed instances found")
            return {'statusCode': 200, 'body': 'No failed instances to process'}
        
        processed_count = 0
        for instance_id, failure_details in failed_instances.items():
            logger.info(f"Processing failed instance: {instance_id}")
            
            try:
                # Analyze the failure for each instance
                failure_analysis = analyze_instance_failure(instance_id, failure_details)
                
                # Get historical remediation data to improve strategy
                historical_data = get_historical_remediation_data(instance_id)
                
                # Determine remediation strategy (enhanced with ML insights)
                remediation_plan = determine_enhanced_remediation_strategy(
                    instance_id, failure_analysis, historical_data
                )
                
                # Record the failure event in DynamoDB
                tracking_record = record_failure_event(
                    execution_id, instance_id, failure_analysis, remediation_plan, dry_run_enabled
                )
                
                # If dry-run is enabled, add it to the remediation plan
                if dry_run_enabled:
                    remediation_plan['dry_run'] = True
                    log_dry_run_simulation(instance_id, remediation_plan)
                
                # Add tracking ID to remediation plan
                remediation_plan['tracking_id'] = tracking_record['tracking_id']
                remediation_plan['historical_insights'] = historical_data.get('insights', {})
                
                # Trigger remediation workflow
                trigger_remediation_workflow(instance_id, remediation_plan, window_id)
                processed_count += 1
                
            except Exception as e:
                logger.error(f"Error processing instance {instance_id}: {str(e)}")
                # Record the processing error
                record_processing_error(execution_id, instance_id, str(e))
                continue
        
        return {
            'statusCode': 200, 
            'body': f'Processed {processed_count} failed instances',
            'dry_run_mode': dry_run_enabled,
            'total_failures': len(failed_instances),
            'processed_successfully': processed_count
        }
        
    except Exception as e:
        logger.error(f"Error processing maintenance window failure: {str(e)}")
        raise

def get_failed_instances(execution_id):
    """Get list of instances that failed during maintenance window execution"""
    try:
        failed_instances = {}
        
        task_executions = ssm.describe_maintenance_window_execution_task_invocations(
            WindowExecutionId=execution_id
        )
        
        for invocation in task_executions.get('WindowExecutionTaskInvocations', []):
            if invocation.get('Status') in ['FAILED', 'TIMED_OUT', 'CANCELLED']:
                parameters = invocation.get('Parameters', {})
                instance_ids = []
                
                # Check different possible parameter structures
                if 'instanceIds' in parameters:
                    instance_ids = parameters['instanceIds']
                elif 'InstanceIds' in parameters:
                    instance_ids = parameters['InstanceIds']
                
                if instance_ids and len(instance_ids) > 0:
                    instance_id = instance_ids[0]
                    failed_instances[instance_id] = {
                        'task_type': invocation.get('TaskType'),
                        'status': invocation.get('Status'),
                        'status_details': invocation.get('StatusDetails', ''),
                        'start_time': invocation.get('StartTime'),
                        'end_time': invocation.get('EndTime'),
                        'task_execution_id': invocation.get('TaskExecutionId')
                    }
        
        return failed_instances
        
    except Exception as e:
        logger.error(f"Error getting failed instances: {str(e)}")
        return {}

def analyze_instance_failure(instance_id, failure_details):
    """Enhanced failure analysis with more context"""
    try:
        instance_info = ec2.describe_instances(InstanceIds=[instance_id])
        
        if not instance_info.get('Reservations') or not instance_info['Reservations'][0].get('Instances'):
            logger.error(f"Instance {instance_id} not found")
            return {
                'instance_id': instance_id,
                'platform': 'Linux',
                'error': 'Instance not found'
            }
            
        instance = instance_info['Reservations'][0]['Instances'][0]
        platform = instance.get('Platform', 'Linux')
        instance_type = instance.get('InstanceType')
        
        # Get command execution details
        task_execution_id = failure_details.get('task_execution_id')
        command_details = {}
        
        if task_execution_id:
            try:
                command_response = ssm.get_command_invocation(
                    CommandId=task_execution_id,
                    InstanceId=instance_id
                )
                
                command_details = {
                    'standard_output': command_response.get('StandardOutputContent', ''),
                    'standard_error': command_response.get('StandardErrorContent', ''),
                    'status': command_response.get('Status'),
                    'status_details': command_response.get('StatusDetails', ''),
                    'execution_start_time': str(command_response.get('ExecutionStartDateTime', '')),
                    'execution_end_time': str(command_response.get('ExecutionEndDateTime', ''))
                }
            except Exception as e:
                logger.warning(f"Could not get command details for {task_execution_id}: {str(e)}")
        
        # Get current patch compliance state
        patch_compliance = get_patch_compliance_state(instance_id)
        
        failure_analysis = {
            'instance_id': instance_id,
            'platform': platform,
            'instance_type': instance_type,
            'vpc_id': instance.get('VpcId'),
            'subnet_id': instance.get('SubnetId'),
            'availability_zone': instance.get('Placement', {}).get('AvailabilityZone'),
            'ami_id': instance.get('ImageId'),
            'failure_status': failure_details.get('status'),
            'failure_details': failure_details.get('status_details'),
            'command_details': command_details,
            'patch_compliance': patch_compliance,
            'timestamp': datetime.utcnow().isoformat(),
            'analysis_version': '2.0'
        }
        
        return failure_analysis
        
    except Exception as e:
        logger.error(f"Error analyzing failure for {instance_id}: {str(e)}")
        return {
            'instance_id': instance_id,
            'platform': 'Linux',
            'error': str(e)
        }

def get_patch_compliance_state(instance_id):
    """Get current patch compliance information"""
    try:
        response = ssm.describe_instance_patch_states(InstanceIds=[instance_id])
        if response.get('InstancePatchStates'):
            patch_state = response['InstancePatchStates'][0]
            return {
                'failed_count': patch_state.get('FailedCount', 0),
                'installed_count': patch_state.get('InstalledCount', 0),
                'missing_count': patch_state.get('MissingCount', 0),
                'not_applicable_count': patch_state.get('NotApplicableCount', 0),
                'operation_end_time': str(patch_state.get('OperationEndTime', '')),
                'operation': patch_state.get('Operation'),
                'patch_group': patch_state.get('PatchGroup')
            }
    except Exception as e:
        logger.warning(f"Could not get patch compliance for {instance_id}: {str(e)}")
    
    return {}

def get_historical_remediation_data(instance_id):
    """Get historical remediation data from DynamoDB for ML insights"""
    try:
        table_name = os.environ.get('DYNAMODB_TABLE_NAME', f'patch-tracking-{os.environ.get("ENVIRONMENT", "prod")}')
        table = dynamodb.Table(table_name)
        
        # Get recent remediation attempts for this instance
        response = table.query(
            KeyConditionExpression='instance_id = :instance_id',
            ExpressionAttributeValues={':instance_id': instance_id},
            ScanIndexForward=False,  # Most recent first
            Limit=10
        )
        
        historical_attempts = response.get('Items', [])
        
        # Analyze patterns
        insights = analyze_historical_patterns(historical_attempts)
        
        return {
            'recent_attempts': historical_attempts,
            'insights': insights,
            'total_attempts': len(historical_attempts)
        }
        
    except Exception as e:
        logger.warning(f"Could not get historical data for {instance_id}: {str(e)}")
        return {'recent_attempts': [], 'insights': {}, 'total_attempts': 0}

def analyze_historical_patterns(historical_attempts):
    """Analyze historical patterns to provide ML insights"""
    if not historical_attempts:
        return {}
    
    insights = {
        'most_successful_strategy': None,
        'failure_patterns': [],
        'success_rate_by_strategy': {},
        'recommendations': []
    }
    
    # Count strategies and their success rates
    strategy_stats = {}
    
    for attempt in historical_attempts:
        strategy = attempt.get('remediation_strategy')
        outcome = attempt.get('final_outcome', 'unknown')
        
        if strategy not in strategy_stats:
            strategy_stats[strategy] = {'total': 0, 'successful': 0}
        
        strategy_stats[strategy]['total'] += 1
        if outcome == 'successful':
            strategy_stats[strategy]['successful'] += 1
    
    # Calculate success rates
    for strategy, stats in strategy_stats.items():
        if stats['total'] > 0:
            success_rate = stats['successful'] / stats['total']
            insights['success_rate_by_strategy'][strategy] = round(success_rate * 100, 1)
    
    # Find most successful strategy
    if insights['success_rate_by_strategy']:
        insights['most_successful_strategy'] = max(
            insights['success_rate_by_strategy'], 
            key=insights['success_rate_by_strategy'].get
        )
    
    # Generate recommendations
    if len(historical_attempts) >= 3:
        recent_failures = [a for a in historical_attempts[:3] if a.get('final_outcome') != 'successful']
        if len(recent_failures) >= 2:
            insights['recommendations'].append('Consider escalating to human operator due to repeated failures')
        
        if insights['most_successful_strategy']:
            insights['recommendations'].append(f'Historical data suggests {insights["most_successful_strategy"]} strategy has highest success rate')
    
    return insights

def determine_enhanced_remediation_strategy(instance_id, failure_analysis, historical_data):
    """Enhanced remediation strategy with ML insights"""
    platform = failure_analysis.get('platform', 'Linux')
    error_output = failure_analysis.get('command_details', {}).get('standard_error', '').lower()
    status_details = failure_analysis.get('failure_details', '').lower()
    
    remediation_plan = {
        'instance_id': instance_id,
        'platform': platform,
        'strategy': 'unknown',
        'confidence_score': 0.5,
        'retry_count': 0,
        'escalate': False,
        'cross_platform_commands': [],
        'ml_insights': historical_data.get('insights', {}),
        'strategy_selection_reason': 'pattern_matching'
    }
    
    # Handle error cases
    if failure_analysis.get('error'):
        remediation_plan.update({
            'strategy': 'escalation',
            'escalate': True,
            'error': failure_analysis.get('error'),
            'confidence_score': 1.0,
            'strategy_selection_reason': 'error_condition'
        })
        return remediation_plan
    
    # Check if historical data suggests escalation
    insights = historical_data.get('insights', {})
    if 'Consider escalating to human operator' in insights.get('recommendations', []):
        remediation_plan.update({
            'strategy': 'escalation',
            'escalate': True,
            'confidence_score': 0.9,
            'strategy_selection_reason': 'historical_pattern_suggests_escalation'
        })
        return remediation_plan
    
    # Use historical insights to inform strategy selection
    preferred_strategy = insights.get('most_successful_strategy')
    
    # Pattern-based strategy selection with confidence scoring
    if 'no space left' in error_output or 'disk full' in error_output:
        strategy = 'disk_space_cleanup'
        confidence = 0.8
        if preferred_strategy == strategy:
            confidence = 0.9
            remediation_plan['strategy_selection_reason'] = 'pattern_matching_with_historical_confirmation'
        
        remediation_plan.update({
            'strategy': strategy,
            'confidence_score': confidence,
            'cross_platform_commands': get_disk_cleanup_commands(platform)
        })
    
    elif 'service' in error_output or 'process' in error_output:
        strategy = 'service_management'
        confidence = 0.7
        if preferred_strategy == strategy:
            confidence = 0.85
            remediation_plan['strategy_selection_reason'] = 'pattern_matching_with_historical_confirmation'
        
        remediation_plan.update({
            'strategy': strategy,
            'confidence_score': confidence,
            'cross_platform_commands': get_service_management_commands(platform)
        })
    
    elif any(keyword in error_output for keyword in ['timeout', 'connection', 'network']):
        strategy = 'network_troubleshooting'
        confidence = 0.6
        if preferred_strategy == strategy:
            confidence = 0.8
            remediation_plan['strategy_selection_reason'] = 'pattern_matching_with_historical_confirmation'
        
        remediation_plan.update({
            'strategy': strategy,
            'confidence_score': confidence,
            'cross_platform_commands': get_network_troubleshooting_commands(platform)
        })
    
    elif 'ssm' in error_output or 'agent' in error_output:
        strategy = 'agent_recovery'
        confidence = 0.8
        if preferred_strategy == strategy:
            confidence = 0.9
            remediation_plan['strategy_selection_reason'] = 'pattern_matching_with_historical_confirmation'
        
        remediation_plan.update({
            'strategy': strategy,
            'confidence_score': confidence,
            'cross_platform_commands': get_agent_recovery_commands(platform)
        })
    
    else:
        # If no clear pattern, use historical insights or escalate
        if preferred_strategy and preferred_strategy != 'escalation':
            remediation_plan.update({
                'strategy': preferred_strategy,
                'confidence_score': 0.6,
                'cross_platform_commands': get_commands_for_strategy(preferred_strategy, platform),
                'strategy_selection_reason': 'historical_data_recommendation'
            })
        else:
            remediation_plan.update({
                'strategy': 'escalation',
                'escalate': True,
                'confidence_score': 0.7,
                'strategy_selection_reason': 'no_clear_pattern_or_historical_guidance'
            })
    
    return remediation_plan

def get_commands_for_strategy(strategy, platform):
    """Get commands for a specific strategy and platform"""
    strategy_map = {
        'disk_space_cleanup': get_disk_cleanup_commands,
        'service_management': get_service_management_commands,
        'network_troubleshooting': get_network_troubleshooting_commands,
        'agent_recovery': get_agent_recovery_commands
    }
    
    if strategy in strategy_map:
        return strategy_map[strategy](platform)
    
    return []

def record_failure_event(execution_id, instance_id, failure_analysis, remediation_plan, dry_run_enabled):
    """Record comprehensive failure event in DynamoDB"""
    try:
        table_name = os.environ.get('DYNAMODB_TABLE_NAME', f'patch-tracking-{os.environ.get("ENVIRONMENT", "prod")}')
        table = dynamodb.Table(table_name)
        
        tracking_id = str(uuid.uuid4())
        timestamp = datetime.utcnow().isoformat()
        
        item = {
            'instance_id': instance_id,
            'timestamp': timestamp,
            'tracking_id': tracking_id,
            'execution_id': execution_id,
            'event_type': 'patch_failure_detected',
            'platform': failure_analysis.get('platform', 'Unknown'),
            'instance_type': failure_analysis.get('instance_type', 'Unknown'),
            'remediation_strategy': remediation_plan.get('strategy'),
            'confidence_score': remediation_plan.get('confidence_score', 0),
            'strategy_selection_reason': remediation_plan.get('strategy_selection_reason', 'unknown'),
            'dry_run_mode': dry_run_enabled,
            'failure_analysis': json.dumps(failure_analysis, default=str),
            'remediation_plan': json.dumps(remediation_plan, default=str),
            'ml_insights': json.dumps(remediation_plan.get('ml_insights', {})),
            'status': 'processing_started',
            'created_at': timestamp,
            'updated_at': timestamp,
            'ttl': int(datetime.utcnow().timestamp()) + (90 * 24 * 60 * 60)  # 90 days TTL
        }
        
        table.put_item(Item=item)
        logger.info(f"Recorded failure event with tracking ID: {tracking_id}")
        
        return {'tracking_id': tracking_id, 'timestamp': timestamp}
        
    except Exception as e:
        logger.error(f"Error recording failure event: {str(e)}")
        return {'tracking_id': str(uuid.uuid4()), 'timestamp': datetime.utcnow().isoformat()}

def record_processing_error(execution_id, instance_id, error_message):
    """Record processing errors in DynamoDB"""
    try:
        table_name = os.environ.get('DYNAMODB_TABLE_NAME', f'patch-tracking-{os.environ.get("ENVIRONMENT", "prod")}')
        table = dynamodb.Table(table_name)
        
        item = {
            'instance_id': instance_id,
            'timestamp': datetime.utcnow().isoformat(),
            'tracking_id': str(uuid.uuid4()),
            'execution_id': execution_id,
            'event_type': 'processing_error',
            'error_message': error_message,
            'status': 'error',
            'created_at': datetime.utcnow().isoformat(),
            'ttl': int(datetime.utcnow().timestamp()) + (30 * 24 * 60 * 60)  # 30 days TTL
        }
        
        table.put_item(Item=item)
        
    except Exception as e:
        logger.error(f"Error recording processing error: {str(e)}")

def log_dry_run_simulation(instance_id, remediation_plan):
    """Enhanced dry-run logging with ML insights"""
    strategy = remediation_plan.get('strategy', 'unknown')
    platform = remediation_plan.get('platform', 'unknown')
    confidence = remediation_plan.get('confidence_score', 0)
    ml_insights = remediation_plan.get('ml_insights', {})
    
    logger.info("=" * 60)
    logger.info("DRY RUN SIMULATION - ENHANCED WITH ML INSIGHTS")
    logger.info("=" * 60)
    logger.info(f"Instance ID: {instance_id}")
    logger.info(f"Platform: {platform}")
    logger.info(f"Strategy: {strategy}")
    logger.info(f"Confidence Score: {confidence:.1%}")
    logger.info(f"Strategy Selection: {remediation_plan.get('strategy_selection_reason', 'unknown')}")
    
    # Log ML insights
    if ml_insights:
        logger.info("ML INSIGHTS:")
        if ml_insights.get('most_successful_strategy'):
            logger.info(f"  Most successful historical strategy: {ml_insights['most_successful_strategy']}")
        
        if ml_insights.get('success_rate_by_strategy'):
            logger.info("  Success rates by strategy:")
            for strat, rate in ml_insights['success_rate_by_strategy'].items():
                logger.info(f"    {strat}: {rate}%")
        
        if ml_insights.get('recommendations'):
            logger.info("  Recommendations:")
            for rec in ml_insights['recommendations']:
                logger.info(f"    - {rec}")
    
    # Log standard simulation actions
    actions_map = {
        'disk_space_cleanup': [
            'Would clean temporary files older than 7 days',
            'Would clean package manager cache',
            'Would remove old log files',
            'Would retry patch operation'
        ],
        'service_management': [
            'Would stop conflicting services',
            'Would apply patches',
            'Would restart services',
            'Would verify service health'
        ],
        'network_troubleshooting': [
            'Would test network connectivity',
            'Would restart network services',
            'Would retry patch operation'
        ],
        'agent_recovery': [
            'Would restart SSM agent',
            'Would verify agent status',
            'Would retry patch operation'
        ],
        'escalation': [
            'Would create AWS Support ticket with Bedrock analysis',
            'Would notify operations team',
            'Would require manual intervention'
        ]
    }
    
    actions = actions_map.get(strategy, ['Would escalate to human operator'])
    
    logger.info("Actions that would be performed:")
    for i, action in enumerate(actions, 1):
        logger.info(f"  {i}. {action}")
    
    # Log platform-specific commands
    commands = remediation_plan.get('cross_platform_commands', [])
    for cmd_set in commands:
        if cmd_set.get('platform') == platform:
            logger.info(f"Platform-specific commands for {platform}:")
            for cmd in cmd_set.get('commands', [])[:3]:
                logger.info(f"  - Would run: {cmd[:60]}{'...' if len(cmd) > 60 else ''}")
    
    logger.info("=" * 60)
    logger.info("NOTE: This is a DRY RUN - no actual changes made")
    logger.info("=" * 60)

# Keep all the existing command generation functions (get_disk_cleanup_commands, etc.)
def get_disk_cleanup_commands(platform):
    """Platform-specific disk cleanup commands"""
    if platform == 'Windows':
        return [{
            'platform': 'Windows',
            'commands': [
                'Get-ChildItem -Path $env:TEMP -Recurse -ErrorAction SilentlyContinue | Where-Object {$_.LastWriteTime -lt (Get-Date).AddDays(-7)} | Remove-Item -Force -Recurse -ErrorAction SilentlyContinue',
                'Get-ChildItem -Path "$env:WINDIR\\Temp" -Recurse -ErrorAction SilentlyContinue | Where-Object {$_.LastWriteTime -lt (Get-Date).AddDays(-7)} | Remove-Item -Force -Recurse -ErrorAction SilentlyContinue',
                'Start-Process -FilePath "cleanmgr" -ArgumentList "/sagerun:1" -Wait -WindowStyle Hidden -ErrorAction SilentlyContinue',
                'Write-Output "Windows disk cleanup completed"'
            ]
        }]
    else:
        return [{
            'platform': 'Linux',
            'commands': [
                'find /tmp -type f -atime +7 -delete 2>/dev/null || true',
                'find /var/tmp -type f -atime +7 -delete 2>/dev/null || true',
                'yum clean all 2>/dev/null || apt-get clean 2>/dev/null || zypper clean 2>/dev/null || true',
                'journalctl --vacuum-time=30d 2>/dev/null || true',
                'find /var/log -name "*.log.*" -mtime +30 -delete 2>/dev/null || true',
                'echo "Linux disk cleanup completed"'
            ]
        }]

def get_service_management_commands(platform):
    """Platform-specific service management commands"""
    if platform == 'Windows':
        return [{
            'platform': 'Windows',
            'commands': [
                'New-Item -ItemType Directory -Path "C:\\temp" -Force -ErrorAction SilentlyContinue',
                '$services = Get-Service -ErrorAction SilentlyContinue | Where-Object {$_.Status -eq "Running" -and $_.Name -match "(IIS|Apache|SQL|W3SVC)"}',
                '$services | ForEach-Object { try { Stop-Service $_.Name -Force -ErrorAction Stop; Write-Output "Stopped service: $($_.Name)" } catch { Write-Output "Failed to stop: $($_.Name)" } }',
                '$services | Select-Object Name | Out-File -FilePath "C:\\temp\\stopped_services.txt" -ErrorAction SilentlyContinue'
            ]
        }]
    else:
        return [{
            'platform': 'Linux',
            'commands': [
                '#!/bin/bash',
                'SERVICES_TO_MANAGE=("httpd" "nginx" "apache2" "mysql" "mysqld" "postgresql")',
                'for service in "${SERVICES_TO_MANAGE[@]}"; do',
                '    if systemctl is-active --quiet "$service" 2>/dev/null; then',
                '        systemctl stop "$service" 2>/dev/null || true',
                '        echo "$service" >> /tmp/stopped_services.txt',
                '        echo "Stopped service: $service"',
                '    fi',
                'done'
            ]
        }]

def get_network_troubleshooting_commands(platform):
    """Platform-specific network troubleshooting commands"""
    if platform == 'Windows':
        return [{
            'platform': 'Windows',
            'commands': [
                'Test-NetConnection -ComputerName "8.8.8.8" -Port 53 -WarningAction SilentlyContinue -ErrorAction SilentlyContinue',
                'try { Resolve-DnsName "google.com" -ErrorAction Stop; Write-Output "DNS resolution: OK" } catch { Write-Output "DNS resolution: Failed" }',
                'ipconfig /flushdns',
                'netsh winsock reset',
                'Write-Output "Windows network troubleshooting completed"'
            ]
        }]
    else:
        return [{
            'platform': 'Linux',
            'commands': [
                '#!/bin/bash',
                'ping -c 3 8.8.8.8 >/dev/null 2>&1 && echo "Connectivity: OK" || echo "Connectivity: Failed"',
                'nslookup google.com >/dev/null 2>&1 && echo "DNS: OK" || echo "DNS: Failed"',
                'systemctl restart network 2>/dev/null || systemctl restart networking 2>/dev/null || echo "Network restart: Not available"',
                'curl -I --connect-timeout 10 https://amazonlinux-2-repos-us-east-1.s3.amazonaws.com/ >/dev/null 2>&1 && echo "Repository: OK" || echo "Repository: Failed"',
                'echo "Linux network troubleshooting completed"'
            ]
        }]

def get_agent_recovery_commands(platform):
    """Platform-specific SSM agent recovery commands"""
    if platform == 'Windows':
        return [{
            'platform': 'Windows',
            'commands': [
                'try { Restart-Service -Name "AmazonSSMAgent" -Force -ErrorAction Stop; Write-Output "SSM Agent restarted" } catch { Write-Output "Failed to restart SSM Agent: $_" }',
                'Start-Sleep -Seconds 10',
                'Get-Service -Name "AmazonSSMAgent" | Select-Object Name, Status',
                'Write-Output "Windows SSM agent recovery completed"'
            ]
        }]
    else:
        return [{
            'platform': 'Linux',
            'commands': [
                'sudo systemctl restart amazon-ssm-agent 2>/dev/null || echo "Failed to restart SSM agent"',
                'sleep 10',
                'sudo systemctl is-active amazon-ssm-agent >/dev/null 2>&1 && echo "SSM Agent: Running" || echo "SSM Agent: Failed"',
                'echo "Linux SSM agent recovery completed"'
            ]
        }]

def trigger_remediation_workflow(instance_id, remediation_plan, window_id):
    """Trigger the Step Functions remediation workflow"""
    try:
        state_machine_arn = os.environ.get('STEP_FUNCTIONS_ARN')
        
        if not state_machine_arn:
            logger.error("STEP_FUNCTIONS_ARN environment variable not set")
            return
        
        input_data = {
            'instance_id': instance_id,
            'remediation_plan': remediation_plan,
            'maintenance_window_id': window_id,
            'timestamp': datetime.utcnow().isoformat(),
            'tracking_id': remediation_plan.get('tracking_id')
        }
        
        execution_name = f"remediation-{instance_id}-{int(datetime.utcnow().timestamp())}"
        
        response = stepfunctions.start_execution(
            stateMachineArn=state_machine_arn,
            name=execution_name,
            input=json.dumps(input_data, default=str)
        )
        
        logger.info(f"Started remediation workflow for {instance_id}: {response['executionArn']}")
        
    except Exception as e:
        logger.error(f"Error starting remediation workflow: {str(e)}")
