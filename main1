import json
import boto3
import logging
import os
from datetime import datetime

# Configure logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Initialize AWS clients
ssm = boto3.client('ssm')
ec2 = boto3.client('ec2')
stepfunctions = boto3.client('stepfunctions')

def lambda_handler(event, context):
    """
    Main function to analyze patch failures and trigger remediation
    Triggered by EventBridge when maintenance windows fail
    
    This function:
    1. Receives EventBridge events from failed maintenance windows
    2. Analyzes which instances failed and why
    3. Determines appropriate remediation strategy
    4. Either logs dry-run simulation OR triggers Step Functions
    
    No existing resources are modified - only reads existing data
    """
    try:
        # Extract maintenance window details from EventBridge event
        detail = event.get('detail', {})
        execution_id = detail.get('maintenance-window-execution-id')
        window_id = detail.get('maintenance-window-id')
        status = detail.get('status')
        
        # Check if dry-run mode is enabled via environment variable
        dry_run_enabled = os.environ.get('DRY_RUN_MODE', 'false').lower() == 'true'
        
        logger.info(f"=== PATCH FAILURE ANALYSIS START ===")
        logger.info(f"Maintenance Window: {window_id}")
        logger.info(f"Execution ID: {execution_id}")
        logger.info(f"Status: {status}")
        logger.info(f"Dry Run Mode: {dry_run_enabled}")
        
        # Only process failures and timeouts - ignore successful executions
        if status not in ['FAILED', 'TIMED_OUT']:
            logger.info(f"Status '{status}' does not require remediation - exiting")
            return {
                'statusCode': 200, 
                'message': 'No remediation required',
                'status': status
            }
        
        # Find all instances that failed in this maintenance window execution
        failed_instances = get_failed_instances(execution_id)
        
        if not failed_instances:
            logger.info("No failed instances found in this execution")
            return {
                'statusCode': 200,
                'message': 'No failed instances to process'
            }
        
        logger.info(f"Found {len(failed_instances)} failed instances")
        
        # Process each failed instance
        processed_count = 0
        for instance_id, failure_info in failed_instances.items():
            logger.info(f"\n--- Processing Instance: {instance_id} ---")
            
            try:
                # Step 1: Analyze what went wrong with this instance
                failure_analysis = analyze_instance_failure(instance_id, failure_info)
                
                if failure_analysis.get('error'):
                    logger.error(f"Could not analyze instance {instance_id}: {failure_analysis['error']}")
                    continue
                
                # Step 2: Determine the best remediation strategy
                remediation_plan = determine_remediation_strategy(failure_analysis)
                
                logger.info(f"Platform: {remediation_plan['platform']}")
                logger.info(f"Strategy: {remediation_plan['strategy']}")
                logger.info(f"Escalate: {remediation_plan.get('escalate', False)}")
                
                # Step 3: Handle dry-run mode
                if dry_run_enabled:
                    remediation_plan['dry_run'] = True
                    log_dry_run_simulation(instance_id, remediation_plan)
                    processed_count += 1
                    continue
                
                # Step 4: Trigger Step Functions for actual remediation
                trigger_step_functions_workflow(instance_id, remediation_plan, window_id)
                processed_count += 1
                
            except Exception as instance_error:
                logger.error(f"Error processing instance {instance_id}: {str(instance_error)}")
                continue
        
        # Return summary
        result = {
            'statusCode': 200,
            'message': f'Successfully processed {processed_count} of {len(failed_instances)} failed instances',
            'dry_run_mode': dry_run_enabled,
            'instances_processed': processed_count,
            'total_failures': len(failed_instances)
        }
        
        logger.info(f"=== PATCH FAILURE ANALYSIS COMPLETE ===")
        logger.info(f"Summary: {result['message']}")
        
        return result
        
    except Exception as main_error:
        logger.error(f"CRITICAL ERROR in patch failure analysis: {str(main_error)}")
        raise

def get_failed_instances(execution_id):
    """
    Get list of EC2 instances that failed during maintenance window execution
    
    Args:
        execution_id: The maintenance window execution ID from EventBridge
        
    Returns:
        dict: {instance_id: failure_details} for all failed instances
        
    Note: Only reads existing SSM data - does not modify anything
    """
    try:
        failed_instances = {}
        
        # Query SSM for task invocations in this maintenance window execution
        response = ssm.describe_maintenance_window_execution_task_invocations(
            WindowExecutionId=execution_id
        )
        
        # Process each task invocation to find failed instances
        for invocation in response.get('WindowExecutionTaskInvocations', []):
            invocation_status = invocation.get('Status')
            
            # Only interested in failures, timeouts, and cancellations
            if invocation_status not in ['FAILED', 'TIMED_OUT', 'CANCELLED']:
                continue
            
            # Extract instance IDs from the task parameters
            parameters = invocation.get('Parameters', {})
            instance_ids = (
                parameters.get('instanceIds') or 
                parameters.get('InstanceIds') or 
                []
            )
            
            # Record failure details for each instance
            if instance_ids:
                instance_id = instance_ids[0]  # Usually one instance per invocation
                failed_instances[instance_id] = {
                    'failure_status': invocation_status,
                    'failure_details': invocation.get('StatusDetails', ''),
                    'task_execution_id': invocation.get('TaskExecutionId'),
                    'task_type': invocation.get('TaskType'),
                    'start_time': invocation.get('StartTime'),
                    'end_time': invocation.get('EndTime')
                }
        
        return failed_instances
        
    except Exception as e:
        logger.error(f"Error retrieving failed instances for execution {execution_id}: {str(e)}")
        return {}

def analyze_instance_failure(instance_id, failure_info):
    """
    Analyze why a specific instance failed patching
    
    Args:
        instance_id: EC2 instance ID
        failure_info: Basic failure information from SSM
        
    Returns:
        dict: Comprehensive failure analysis including platform, errors, etc.
        
    Note: Only reads instance data - does not modify the instance
    """
    try:
        # Get basic instance information from EC2 API
        ec2_response = ec2.describe_instances(InstanceIds=[instance_id])
        
        # Validate response structure
        if not ec2_response.get('Reservations') or not ec2_response['Reservations'][0].get('Instances'):
            logger.error(f"Instance {instance_id} not found in EC2")
            return {
                'instance_id': instance_id,
                'platform': 'Linux',  # Default fallback
                'error': 'Instance not found in EC2'
            }
        
        # Extract instance details
        instance = ec2_response['Reservations'][0]['Instances'][0]
        platform = instance.get('Platform', 'Linux')  # Windows instances have Platform=Windows
        instance_type = instance.get('InstanceType')
        availability_zone = instance.get('Placement', {}).get('AvailabilityZone')
        
        logger.info(f"Instance details - Platform: {platform}, Type: {instance_type}, AZ: {availability_zone}")
        
        # Get detailed command execution information if available
        command_details = {}
        task_execution_id = failure_info.get('task_execution_id')
        
        if task_execution_id:
            try:
                # Get the actual command output and errors
                command_response = ssm.get_command_invocation(
                    CommandId=task_execution_id,
                    InstanceId=instance_id
                )
                
                command_details = {
                    'command_status': command_response.get('Status'),
                    'standard_output': command_response.get('StandardOutputContent', '')[:1000],  # Limit size
                    'standard_error': command_response.get('StandardErrorContent', '')[:1000],   # Limit size
                    'execution_start': str(command_response.get('ExecutionStartDateTime', '')),
                    'execution_end': str(command_response.get('ExecutionEndDateTime', ''))
                }
                
                logger.info(f"Retrieved command execution details for task {task_execution_id}")
                
            except Exception as cmd_error:
                logger.warning(f"Could not retrieve command details for task {task_execution_id}: {str(cmd_error)}")
                command_details = {'error': f'Could not retrieve command details: {str(cmd_error)}'}
        
        # Build comprehensive failure analysis
        analysis = {
            'instance_id': instance_id,
            'platform': platform,
            'instance_type': instance_type,
            'availability_zone': availability_zone,
            'ami_id': instance.get('ImageId'),
            'instance_state': instance.get('State', {}).get('Name'),
            'failure_status': failure_info.get('failure_status'),
            'failure_details': failure_info.get('failure_details', ''),
            'task_type': failure_info.get('task_type'),
            'command_details': command_details,
            'analysis_timestamp': datetime.utcnow().isoformat()
        }
        
        return analysis
        
    except Exception as e:
        logger.error(f"Error analyzing failure for instance {instance_id}: {str(e)}")
        return {
            'instance_id': instance_id,
            'platform': 'Linux',  # Safe fallback
            'error': f'Analysis failed: {str(e)}'
        }

def determine_remediation_strategy(failure_analysis):
    """
    Determine the best remediation strategy based on failure analysis
    
    Args:
        failure_analysis: Output from analyze_instance_failure()
        
    Returns:
        dict: Remediation plan with strategy and escalation flags
        
    This uses pattern matching on error messages to suggest remediation approaches
    """
    instance_id = failure_analysis['instance_id']
    platform = failure_analysis['platform']
    
    # Start with basic remediation plan
    remediation_plan = {
        'instance_id': instance_id,
        'platform': platform,
        'strategy': 'unknown',
        'escalate': False,
        'reason': 'Pattern analysis'
    }
    
    # Handle cases where analysis failed
    if failure_analysis.get('error'):
        logger.warning(f"Instance analysis had errors: {failure_analysis['error']}")
        remediation_plan.update({
            'strategy': 'escalation',
            'escalate': True,
            'reason': f"Analysis error: {failure_analysis['error']}"
        })
        return remediation_plan
    
    # Get error text from command execution for pattern matching
    command_details = failure_analysis.get('command_details', {})
    error_text = (
        command_details.get('standard_error', '') + ' ' +
        failure_analysis.get('failure_details', '')
    ).lower()
    
    logger.info(f"Analyzing error patterns in: {error_text[:200]}...")
    
    # Pattern-based remediation strategy selection
    if any(pattern in error_text for pattern in ['no space left', 'disk full', 'insufficient space']):
        remediation_plan.update({
            'strategy': 'disk_space_cleanup',
            'reason': 'Detected disk space issues in error output'
        })
        logger.info("Selected strategy: disk_space_cleanup (disk space issues detected)")
        
    elif any(pattern in error_text for pattern in ['service', 'process', 'locked', 'busy']):
        remediation_plan.update({
            'strategy': 'service_management',
            'reason': 'Detected service/process conflicts in error output'
        })
        logger.info("Selected strategy: service_management (service conflicts detected)")
        
    elif any(pattern in error_text for pattern in ['timeout', 'connection', 'network', 'unreachable']):
        remediation_plan.update({
            'strategy': 'network_troubleshooting',
            'reason': 'Detected network/connectivity issues in error output'
        })
        logger.info("Selected strategy: network_troubleshooting (network issues detected)")
        
    elif any(pattern in error_text for pattern in ['ssm', 'agent', 'daemon']):
        remediation_plan.update({
            'strategy': 'agent_recovery',
            'reason': 'Detected SSM agent issues in error output'
        })
        logger.info("Selected strategy: agent_recovery (SSM agent issues detected)")
        
    else:
        # No clear pattern detected - escalate to human/support ticket
        remediation_plan.update({
            'strategy': 'escalation',
            'escalate': True,
            'reason': 'No clear error pattern detected for automated remediation'
        })
        logger.info("Selected strategy: escalation (no clear pattern detected)")
    
    return remediation_plan

def log_dry_run_simulation(instance_id, remediation_plan):
    """
    Log detailed dry-run simulation showing what would happen
    
    Args:
        instance_id: EC2 instance ID
        remediation_plan: The remediation plan that would be executed
        
    This provides detailed visibility into what the automation would do
    without actually doing it - safe for testing and validation
    """
    strategy = remediation_plan.get('strategy', 'unknown')
    platform = remediation_plan.get('platform', 'unknown')
    reason = remediation_plan.get('reason', 'No reason provided')
    
    logger.info("=" * 80)
    logger.info("üîç DRY RUN SIMULATION - NO ACTUAL CHANGES WILL BE MADE")
    logger.info("=" * 80)
    logger.info(f"Instance ID: {instance_id}")
    logger.info(f"Platform: {platform}")
    logger.info(f"Selected Strategy: {strategy}")
    logger.info(f"Selection Reason: {reason}")
    logger.info("-" * 80)
    
    # Define what each strategy would do
    strategy_actions = {
        'disk_space_cleanup': [
            'üóëÔ∏è  Clean temporary files older than 7 days (/tmp, /var/tmp, %TEMP%)',
            'üóëÔ∏è  Clean package manager cache (yum, apt, chocolatey)',
            'üóëÔ∏è  Remove old log files and journal entries',
            'üóëÔ∏è  Clean Windows Update cache (if Windows)',
            'üîÑ Wait 5 minutes for cleanup to complete',
            'üîÑ Restart any stopped services',
            'ü©π Retry the original patch operation',
            '‚úÖ Verify patch compliance status'
        ],
        'service_management': [
            'üõë Identify services that may conflict with patching',
            'üõë Gracefully stop conflicting services (IIS, Apache, MySQL, etc.)',
            'üìù Save list of stopped services for later restart',
            'üîÑ Wait 5 minutes for services to stop cleanly', 
            'üîÑ Restart stopped services after patching',
            'ü©π Retry the original patch operation',
            '‚úÖ Verify all services are running properly',
            '‚úÖ Verify patch compliance status'
        ],
        'network_troubleshooting': [
            'üåê Test basic network connectivity (ping 8.8.8.8)',
            'üåê Test DNS resolution (nslookup google.com)',
            'üåê Flush DNS cache',
            'üåê Test repository connectivity',
            'üîÑ Restart network services if needed',
            'üîÑ Wait 3 minutes for network stabilization',
            'ü©π Retry the original patch operation',
            '‚úÖ Verify patch compliance status'
        ],
        'agent_recovery': [
            'üîß Stop SSM Agent service',
            '‚è±Ô∏è  Wait 10 seconds',
            'üîß Start SSM Agent service',
            '‚è±Ô∏è  Wait 15 seconds for agent initialization',
            'üîç Verify SSM Agent is running and responsive',
            'ü©π Retry the original patch operation',
            '‚úÖ Verify patch compliance status'
        ],
        'escalation': [
            'üö® Create AWS Support ticket using Bedrock AI analysis',
            'üìß Send notification to operations team',
            'üìã Include comprehensive failure analysis in ticket',
            '‚è≥ Wait for human intervention',
            'üìù Log escalation for future pattern analysis'
        ]
    }
    
    actions = strategy_actions.get(strategy, ['‚ùì Unknown strategy - would escalate to human operator'])
    
    logger.info("üìã ACTIONS THAT WOULD BE PERFORMED:")
    for i, action in enumerate(actions, 1):
        logger.info(f"   {i:2d}. {action}")
    
    logger.info("-" * 80)
    logger.info(f"‚è±Ô∏è  ESTIMATED DURATION: {get_estimated_duration(strategy)} minutes")
    logger.info("-" * 80)
    logger.info("üõ°Ô∏è  SAFETY NOTE: This is a DRY RUN simulation only")
    logger.info("üõ°Ô∏è  No actual changes were made to any systems")
    logger.info("üõ°Ô∏è  To execute actual remediation, set DRY_RUN_MODE=false")
    logger.info("=" * 80)

def get_estimated_duration(strategy):
    """Get estimated duration for each remediation strategy"""
    durations = {
        'disk_space_cleanup': '10-15',
        'service_management': '8-12', 
        'network_troubleshooting': '5-8',
        'agent_recovery': '3-5',
        'escalation': '1-2'
    }
    return durations.get(strategy, '5-10')

def trigger_step_functions_workflow(instance_id, remediation_plan, window_id):
    """
    Trigger Step Functions workflow to perform actual remediation
    
    Args:
        instance_id: EC2 instance ID to remediate
        remediation_plan: The remediation strategy and details
        window_id: Original maintenance window ID
        
    This starts the Step Functions state machine that will:
    1. Execute the appropriate SSM documents
    2. Monitor progress and retry if needed
    3. Escalate to Bedrock support ticket if remediation fails
    """
    try:
        # Get Step Functions ARN from environment variable
        state_machine_arn = os.environ.get('STEP_FUNCTIONS_ARN')
        
        if not state_machine_arn:
            logger.error("‚ùå STEP_FUNCTIONS_ARN environment variable not configured")
            raise ValueError("Step Functions ARN not configured in Lambda environment")
        
        # Prepare minimal input payload for Step Functions
        workflow_input = {
            'instance_id': instance_id,
            'remediation_plan': remediation_plan,
            'maintenance_window_id': window_id,
            'timestamp': datetime.utcnow().isoformat(),
            'trigger_source': 'patch_failure_analysis'
        }
        
        # Create unique execution name (Step Functions requires unique names)
        execution_name = f"patch-remediation-{instance_id}-{int(datetime.utcnow().timestamp())}"
        
        # Start the Step Functions execution
        response = stepfunctions.start_execution(
            stateMachineArn=state_machine_arn,
            name=execution_name,
            input=json.dumps(workflow_input, default=str)
        )
        
        execution_arn = response['executionArn']
        logger.info(f"‚úÖ Successfully started Step Functions workflow for instance {instance_id}")
        logger.info(f"   Execution ARN: {execution_arn}")
        logger.info(f"   Strategy: {remediation_plan['strategy']}")
        logger.info(f"   Platform: {remediation_plan['platform']}")
        
        return execution_arn
        
    except Exception as e:
        logger.error(f"‚ùå Failed to trigger Step Functions workflow for instance {instance_id}: {str(e)}")
        raise
